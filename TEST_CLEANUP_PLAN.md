# AURORA Test Suite Cleanup Plan

**Goal:** Systematic cleanup to maintain robust, maintainable test coverage without redundancy or over-engineering.

**Date:** 2025-01-26
**Status:** DRAFT - Awaiting approval

---

## Current State Analysis

### Test Suite Inventory
- **Total test files:** 92
  - Unit: 55 files
  - Integration: 19 files
  - E2E: 2 files
  - Performance: 8 files
  - Fault Injection: 5 files
  - Calibration: 1 file
  - Archived: 2 files

- **Total tests:** ~1,800+ test methods
- **Current coverage:** 74.95% (down from 84%)
- **CI Status:**
  - âœ… Python 3.10: All pass
  - âŒ Python 3.11: 28 failures
  - âŒ Python 3.12: 27 failures

### Root Problems Identified

1. **Over-Mocking in Unit Tests**
   - 50+ tests use `@patch` decorators
   - Tests break on Python version changes (not actual bugs)
   - Tests verify implementation details, not behavior
   - Example: `test_init_creates_components` checks constructor calls

2. **Redundant Test Coverage**
   - Same behavior tested at unit, integration, AND implementation level
   - Example: `_validate_safety()` tested separately AND through `execute()`
   - Multiple tests for internal query formatting (implementation detail)

3. **Missing Integration/E2E Tests**
   - Only 2 E2E test files for entire framework
   - Heavy unit testing, light integration testing
   - Inverted pyramid (should be: E2E > Integration > Unit)

4. **Fragile Test Infrastructure**
   - Coverage dropped when switching from `@patch` to DI
   - Tests don't exercise real code paths
   - False confidence from mocked tests

---

## Testing Principles (Going Forward)

### Test Pyramid (Target Distribution)

```
         E2E (10-15%)           â† Test complete workflows
        /          \
   Integration (30-40%)         â† Test component interaction
      /              \
   Unit (50-60%)                â† Test complex logic only
```

**Current:** 95% unit, 4% integration, 1% E2E (INVERTED!)

### What TO Test

**Critical Behaviors (MUST HAVE):**
1. âœ… Safety: Block execution on protected branches
2. âœ… Safety: Validate prompt format before execution
3. âœ… Memory: Store and retrieve code chunks correctly
4. âœ… Memory: ACT-R activation scoring produces correct ranks
5. âœ… SOAR: 9-phase pipeline executes in order
6. âœ… Query: Context retrieval returns relevant results
7. âœ… Budget: Track and limit API costs
8. âœ… MCP: Tools work without API keys
9. âœ… Error Handling: Graceful degradation on failures

**Complex Logic (SHOULD TEST):**
- Algorithm correctness (activation scoring, semantic search)
- Edge cases in parsing/chunking
- Budget calculations and limits
- Error recovery logic

### What NOT to Test

**Implementation Details:**
- âŒ Constructor calls (`assert mock_git.called`)
- âŒ Internal method call order
- âŒ Private method internals (test via public API)
- âŒ Query string formatting (test result, not format)
- âŒ Mock setup verification

**Already Covered Elsewhere:**
- âŒ Behaviors tested at higher level (E2E covers it)
- âŒ Framework features (pytest, SQLite, tree-sitter)
- âŒ Type correctness (mypy handles this)

---

## Cleanup Action Plan

### Phase 1: Triage & Delete (Week 1)

**Objective:** Remove low-value tests, reduce noise

**Actions:**

1. **Delete Redundant Tests** (~10-15 test methods)
   ```
   DELETE tests/unit/soar/headless/test_orchestrator.py:
   - TestHeadlessOrchestratorInit::test_init_creates_components
     (tests constructor calls - implementation detail)

   - TestBuildIterationQuery::test_build_query_truncates_long_scratchpad
     (tests internal formatting - not behavior)

   - TestBuildIterationQuery::test_build_query_with_prompt_data
     (tests query string content - implementation detail)

   KEEP TestBuildIterationQuery::test_build_query_includes_goal
     (behavior: query must include goal to function)
   ```

2. **Delete Duplicate Coverage** (~5-10 test methods)
   ```
   DELETE tests/unit/soar/headless/test_orchestrator.py:
   - TestValidateSafety::test_validate_safety_success
     (already covered by TestExecute::test_execute_success_*)

   - TestLoadPrompt::test_load_prompt_success
     (already covered by integration tests)
   ```

3. **Archive Low-Priority Tests** (move, don't delete)
   ```
   MOVE tests/performance/* to tests/archive/performance/
   - Keep test_activation_benchmarks.py (critical algorithm)
   - Archive others (run manually for optimization work)
   ```

**Expected Result:**
- Remove ~20-25 test methods
- Reduce test execution time by 15-20%
- Maintain all critical behavior coverage

### Phase 2: Fix Fragile Tests (Week 1-2)

**Objective:** Convert remaining valuable tests to DI pattern

**Actions:**

1. **Update test_orchestrator.py** (~16-20 test methods)
   ```python
   # BEFORE (fragile):
   @patch("aurora_soar.headless.orchestrator.GitEnforcer")
   def test_validate_safety_git_error(self, mock_git_class, ...):
       mock_git = Mock()
       mock_git.validate.side_effect = GitBranchError("...")
       mock_git_class.return_value = mock_git
       orchestrator = HeadlessOrchestrator(...)
       # Test expects exception but mock doesn't work on Py 3.11/3.12

   # AFTER (robust):
   def test_validate_safety_git_error(self, ...):
       mock_git = Mock()
       mock_git.validate.side_effect = GitBranchError("...")
       # Inject mock directly
       orchestrator = HeadlessOrchestrator(..., git_enforcer=mock_git)
       # Works on all Python versions
   ```

2. **Classes to update:**
   - TestValidateSafety (2 remaining tests after deletes)
   - TestLoadPrompt (1 remaining test)
   - TestInitializeScratchpad (1 test)
   - TestRunMainLoop (6 tests)
   - TestExecuteIteration (1 test)
   - TestCheckBudget (3 tests)
   - TestEvaluateGoalAchievement (5 tests)

3. **Validation:**
   ```bash
   # Must pass on all versions
   python3.10 -m pytest tests/unit/soar/headless/test_orchestrator.py
   python3.11 -m pytest tests/unit/soar/headless/test_orchestrator.py
   python3.12 -m pytest tests/unit/soar/headless/test_orchestrator.py
   ```

**Expected Result:**
- All orchestrator tests pass on Python 3.10/3.11/3.12
- No `@patch` decorators in orchestrator tests
- Clean, maintainable test code

### Phase 3: Add Missing Integration Tests (Week 2)

**Objective:** Fill gaps in integration/E2E coverage

**Actions:**

1. **Add Critical Integration Tests** (~5-7 new tests)
   ```python
   # tests/integration/test_headless_safety.py
   def test_headless_rejects_main_branch_real_git():
       """Integration: Real git repo + real enforcer = real failure"""
       with tempfile.TemporaryDirectory() as tmpdir:
           # Create real git repo on main branch
           subprocess.run(["git", "init"], cwd=tmpdir)
           subprocess.run(["git", "checkout", "-b", "main"], cwd=tmpdir)

           # Create orchestrator with real components
           orchestrator = HeadlessOrchestrator(...)

           # Should fail with GitBranchError
           with pytest.raises(GitBranchError, match="main"):
               orchestrator.execute()
   ```

2. **New integration tests needed:**
   - Headless execution safety (real git + real enforcer)
   - Memory indexing + retrieval (real parser + real storage)
   - SOAR pipeline (real components, mocked LLM)
   - Budget enforcement (real tracker, mocked API calls)
   - MCP tools workflow (index â†’ search â†’ get â†’ query)

3. **Add E2E tests** (~2-3 new tests)
   ```python
   # tests/e2e/test_complete_workflows.py
   def test_index_search_query_workflow():
       """E2E: Complete MCP workflow without mocks"""
       # Real components, real files, no API key
       # Index codebase â†’ search â†’ get results â†’ verify correct
   ```

**Expected Result:**
- Integration coverage: 30-40% of tests
- E2E coverage: 10-15% of tests
- Higher confidence in real-world behavior

### Phase 4: Documentation & CI (Week 2-3)

**Objective:** Prevent regression, document principles

**Actions:**

1. **Create TESTING.md**
   ```markdown
   # AURORA Testing Guide

   ## Principles
   - Test behavior, not implementation
   - Minimize mocking (prefer real components)
   - Integration > Unit for confidence

   ## When to Write Tests
   - New feature: E2E test + integration test
   - Bug fix: Add failing test first
   - Complex logic: Unit test for edge cases

   ## Anti-Patterns to Avoid
   - Testing constructor calls
   - Testing private methods directly
   - Mocking >2 dependencies
   - Testing framework behavior
   ```

2. **Update CI configuration**
   ```yaml
   # .github/workflows/ci.yml

   # Separate test categories
   - name: Run critical tests (fast)
     run: pytest tests/ -m "critical and not ml"

   - name: Run unit tests
     run: pytest tests/unit/ -m "not ml"

   - name: Run integration tests
     run: pytest tests/integration/ -m "not ml"

   - name: Run E2E tests
     run: pytest tests/e2e/ -m "not ml"
   ```

3. **Add test markers**
   ```python
   # pytest.ini
   markers =
       critical: Critical safety/correctness tests (always run)
       slow: Slow tests (run in nightly builds)
       ml: Requires ML dependencies
       integration: Integration tests
       e2e: End-to-end tests
   ```

4. **Update coverage threshold**
   ```ini
   # pytest.ini
   # Realistic threshold after cleanup
   --cov-fail-under=80  # Was 84, now honest
   ```

**Expected Result:**
- Clear testing standards documented
- CI runs tests in logical groups
- Faster feedback loop
- Sustainable test suite

---

## Success Metrics

**Quantitative:**
- âŒ Before: 1,800+ tests, 28 failures on Python 3.11/3.12
- âœ… After: ~1,650 tests, 0 failures on all versions
- âŒ Before: 74.95% coverage (false negative)
- âœ… After: 80% coverage (honest, realistic)
- âŒ Before: 95% unit, 4% integration, 1% E2E
- âœ… After: 55% unit, 35% integration, 10% E2E

**Qualitative:**
- âœ… All critical behaviors tested at integration/E2E level
- âœ… No `@patch` decorators in new tests
- âœ… Tests pass on Python 3.10/3.11/3.12/3.13
- âœ… Test suite maintainable (1 test = 1 behavior)
- âœ… Fast feedback (<2min for unit tests)

---

## Risk Analysis

**Risks of This Approach:**
1. **Temporarily lower coverage** during transition
   - Mitigation: Do cleanup in feature branch, verify before merge

2. **Might delete useful tests**
   - Mitigation: Archive first (don't delete), can restore if needed

3. **Time investment** (2-3 weeks)
   - Mitigation: Work incrementally, merge in phases

**Risks of NOT Doing This:**
1. âŒ CI/CD blocked on false negatives
2. âŒ Can't ship on Python 3.11/3.12
3. âŒ Test maintenance burden grows with every feature
4. âŒ False confidence from mocked tests
5. âŒ Eventually abandon test suite as unmaintainable

---

## Timeline & Milestones

**Week 1:**
- âœ… Phase 1 complete: Delete redundant tests
- âœ… Phase 2 started: Fix 50% of fragile tests
- ğŸ¯ Milestone: Python 3.10 CI green

**Week 2:**
- âœ… Phase 2 complete: All fragile tests fixed
- âœ… Phase 3 started: Add integration tests
- ğŸ¯ Milestone: All Python versions CI green

**Week 3:**
- âœ… Phase 3 complete: Integration/E2E coverage adequate
- âœ… Phase 4 complete: Documentation & CI improvements
- ğŸ¯ Milestone: Test suite sustainable for MVP development

---

## Approval & Next Steps

**Decision Required:**
- â˜ Approve this cleanup plan
- â˜ Approve deletion of low-value tests
- â˜ Approve timeline (2-3 weeks)
- â˜ Approve reduced coverage threshold (84% â†’ 80%)

**Upon Approval:**
1. Create feature branch `test/cleanup-systematic`
2. Execute Phase 1 (triage & delete)
3. Execute Phase 2 (fix fragile tests)
4. PR review & merge
5. Continue with Phases 3-4

**Immediate Actions (if approved):**
```bash
git checkout -b test/cleanup-systematic
# Start with Phase 1: Delete redundant tests
```
